Neste capítulo será discutida em mais detalhes a abordagem proposta, as justificativas para sua adoção, bem como as técnicas que foram aplicadas e a preparação dos experimentos realizados.

Esta pesquisa propõe-se a realizar o reconhecimento da linguagem de sinais a partir de uma perspectiva estritamente linguística, baseada nos constituintes fonológicos mínimos que descrevem os sinais, e centrada no aprendizado das complexidades e regras que convém contexto e dá significado a eles.

Isso assemelha-se à forma como hoje outras línguas são abordadas com sucesso pelo \acrfull{nlp} e diferencia-se daquela predominante no \acrfull{slr} que, por sua vez, trata os sinais como gestos não-estruturados, mapeados a partir de dados brutos capturados dos indivíduos -- como pixels de imagens ou \textit{frames} de vídeos, pontos lidos de luvas eletrônicas, coordenadas 2D ou 3D, entre outros -- e colocam em segundo plano a importância linguística do sinal.


A hipótese deste trabalho assume que, além de deixar de abordar uma parte muito importante dessa língua, lidar com esse tipo de dados brutos traz complexidades adicionais que extrapolam o escopo que deveria ser efetivamente abordado pelo \acrshort{slr}.
Em outras palavras, esse foco inadequado faz com que pesquisas em \acrshort{slr} deixem de solucionar um problema intrinsecamente de \acrshort{nlp} e passem a investir esforços consideráveis tentando lidar com um conjunto de desafios pertinentes à área de \acrfull{cv} -- os quais comumente já estão abordados ou solucionados por uma de suas subáreas, como a detecção, segmentação e rastreamento de partes do corpo em imagens e vídeos; a interação entre mãos e oclusões decorrentes disso; as variações de tom de pele, cores de roupa e luminosidade do ambiente; entre outros listados nas revisões literárias elaboradas no decorrer da última década para a \acrshort{slr} \cite{papastratis-2021-ai-technologies-sl,rastgoo-2021-slr-deep-survey,koller-2020-quantitative-survey-slr,bragg-2019-slr-interdisciplinary,wadhawan-2019-slr-literature-review,suharjito-2018-feature-extraction-survey,joksimoski-2022-scoping-review,cooper-2011-slr}.


Alguns exemplos populares desses problemas sendo consistentemente endereçados dentro da \acrshort{cv} incluem as ferramentas OpenPose~\cite{wei-2016-conv-machines-openpose,cao-2017-openpose,simon-2017-openpose-hand-face} e MediaPipe~\cite{lugaresi-2019-mediapipe,bazarevsky-2019-mediapipe-blazeface,vakunov-2020-mediapipe-hands,bazarevsky-2020-mediapipe-blazepose}, desenvolvidas pela Carnegie Mellon University e Google Research, respectivamente.
Ambas são o resultado de anos de pesquisa em torno de tais questões, as quais alcançaram um nível de maturidade elevado capaz de abordar em tempo real tarefas de estimativa de pose e rastreamento do corpo, mãos e face (inclusive envolvendo múltiplos indivíduos) de forma robusta a variações corporais, de luminosidade e de ambientes, utilizando apenas uma câmera comum RGB.
Elas estão disponíveis abertamente\footnote{
    O OpenPose está disponível em \url{https://github.com/CMU-Perceptual-Computing-Lab/openpose} e o MediaPipe em \url{https://mediapipe.dev/}.
} e a reutilização desse conhecimento nas etapas para capturar e gerar \textit{features} de níveis mais elevados para o \acrshort{slr} certamente contribuirá para progressos mais efetivos.


Fazendo uma analogia com outras tarefas de \acrshort{nlp}, abordar a língua de sinais por meio dos dados brutos como discutido acima e lidar com os desafios apresentados, por exemplo, possui uma complexidade equivalente a tentar interpretar textos manuscritos apenas rastreando-se o movimento da mão do autor enquanto ele desenha as letras no papel -- ao invés de simplesmente escanear o texto final escrito como entrada para isso; ou ainda, tentar reconhecer a fala de um indivíduo apenas realizando a detecção e o rastreamento dos movimentos de seus lábios -- ao invés de considerar os sinais de áudio capturados para tal.


Como resultado desse enquadramento inadequado por parte das pesquisas em \acrshort{slr}, no decorrer das últimas décadas constata-se um progresso pouco expressivo dessa área sobretudo nos aspectos da linguagem e aplicabilidade no mundo real, acerca do qual \citeonline{selvaraj-2022-openhands,yin-2021-sl-in-nlp,cooper-2011-slr} reiteram:


\begin{citacao}
    Quando comparado com a pesquisa de \acrlong{nlp} baseada em texto e fala, o progresso das pesquisas para línguas de sinais está significativamente atrasado. \cite[tradução nossa]{selvaraj-2022-openhands,yin-2021-sl-in-nlp}
\end{citacao}

\begin{citacao}
    Enquanto sistemas de reconhecimento da fala avançaram ao ponto de estarem comercialmente disponíveis, o reconhecimento de sinais ainda está em sua infância.
    Atualmente, todos os serviços comerciais de tradução de sinais são baseados em humanos e requerem que pessoal especializado esteja disponível, o que os tornam caros e pouco acessíveis. \cite[tradução nossa]{cooper-2011-slr}
\end{citacao}


Dessa forma, considerando a discussão desenvolvida até aqui, nesta pesquisa a \acrshort{slr} será posicionada como uma tarefa de \acrshort{nlp}, delimitando-se seu escopo ao âmbito da linguística e representando-se os sinais através de seus fonemas. Além disso, será aplicado o conhecimento disponibilizado pelas ferramentas acima para criar \textit{features} que representem estes fonemas, viabilizando este processo.
Com isso, objetiva-se eliminar o escopo pertinente a outras áreas de pesquisa e concentrar a capacidade dos modelos aplicados ao aprendizado das regras e restrições linguísticas da língua de sinais.

Tal estratégia de abordar a linguagem por meio de suas unidades constituintes mínimas é também observada em outras tarefas de \acrshort{nlp}. \citeonline{jurafsky-2022-speech-lang-processing} afirmam que a ideia da palavra falada ser composta por unidades menores da fala é adotada, por exemplo, por algoritmos utilizados em tarefas de reconhecimento de fala e de conversão de texto em voz.
Observe na \autoref{fig:exemplo-waveform-phone} o exemplo ilustrado pelos autores da forma de onda da fala para a sentença em inglês ``\textit{she just had a baby}'' (ou ``ela acabou de ter um bebê'').
Cada trecho é rotulado na linha inferior com suas respectivas partículas mínimas de som (ou ``fones''), as quais são transcritas utilizando-se o ARPAbet\footnote{
    ARPAbet é um alfabeto fonético simples introduzido por \citeonline{shoup-1980-arpabet} que utiliza símbolos ASCII para representar um subconjunto do \acrshort{ipa} que se refere ao idioma inglês-americano. O \acrfull{ipa}, por sua vez, é a representação fonética padrão para a transcrição das línguas ao redor do mundo \cite{jurafsky-2022-speech-lang-processing}.
}. Esse tipo de partícula é comumente utilizado como \textit{feature} de entrada para tarefas envolvendo o processamento da fala.


\figura[p. 586]
{fig:exemplo-waveform-phone}
{capitulos/metodos/imagens/exemplo_waveform_phone}
{width=0.90\textwidth}
{Formas de onda da fala para a sentença ``\textit{she just had a baby}'' (primeira linha) rotuladas com suas respectivas partículas de som transcritas em ARPAbet (linha inferior)}
{jurafsky-2022-speech-lang-processing}



No caso da abordagem proposta aqui, essas partículas serão substituídas por alguns dos parâmetros fonológicos introduzidos na \autoref{sec:linguistica}. Uma vez que não há \textit{datasets} disponíveis com esse tipo de representação para as línguas de sinais, o primeiro passo consistirá em gerar esse \textit{dataset}. Para isso, o \acrshort{asllvd} será adotado como \textit{dataset} base e suas amostras serão processadas utilizando-se o OpenPose, o qual fornece coordenadas que possibilitam a extração de \textit{features} fonológicas de nível semântico mais elevado.
Em seguida, serão aplicados modelos de \acrfull{ml} comumente utilizados em tarefas de \acrshort{nlp}, com o intuito de avaliar seu desempenho neste contexto e a eficácia da abordagem proposta. 



A \autoref{fig:etapas-abordagem} ilustra essa abordagem, a qual é divida em duas etapas.
No bloco à esquerda, observa-se o processo envolvido na geração do \textit{dataset}, que inicia-se pelas amostras do \acrshort{asllvd}, contempla a obtenção de coordenadas 3D por meio de ferramentas de \acrshort{cv} e finaliza com a geração do ASL-Phono, que contém os respectivos atributos fonológicos.
No bloco à direita, está a etapa de \acrlong{slr}, que engloba a preparação das \textit{features}, o processamento dessas \textit{features} pelos modelos de \acrshort{ml} e a classificação dos sinais.
Todas essas etapas serão discutidas em detalhes nas seções a seguir.

\figura
{fig:etapas-abordagem}
{capitulos/metodos/imagens/etapas_abordagem}
{width=0.95\textwidth}
{Etapas envolvidas na abordagem proposta}
{}
