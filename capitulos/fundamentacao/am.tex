\section{Aprendizagem de máquina}
\label{sec:am}

\citeonline{quiza-2012-finite-element,russell-2010-modern-approach} definem formalmente a \acrfull{ia} como um ramo da ciência da computação que visa estudar e projetar agentes inteligentes, ou seja, sistemas capazes de perceber seu ambiente e realizar ações que maximizam suas chances de sucesso.
A \acrfull{ml}, por sua vez, é definida por \citeonline{murphy-2012-ml-probabilistic,goodfellow-2016-deep-learning} como uma área que estuda um conjunto de algoritmos de \acrshort{ia} capazes de detectar automaticamente padrões a partir de dados e, em seguida, utilizá-los para prever dados futuros ou realizar tomadas de decisões.
Esses algoritmos comumente adotam modelos estatísticos para realizar análises e inferências sobre esses dados e não necessitam que instruções explícitas sejam programadas para que consigam detectar esses padrões.


Segundo \citeonline{mitchell-1997-ml,bishop-2006-pattern-recognition}, os algoritmos de \acrshort{ml} constituem-se de um tipo de estrutura denominado \acrfull{ann}. Essa estrutura é inspirada pela observação dos sistemas de aprendizado biológico, os quais são compostos de redes muito complexas de neurônios interconectados entre si, conforme ilustra a \autoref{fig:exemplo-neuronios}.

\figura[p. 40]
    {fig:exemplo-neuronios} % Label
    {capitulos/fundamentacao/imagens/exemplo_neuronios} % Path
    {height=5cm} % Size
    {Exemplo de neurônios interconectados, que compõem os sistemas biológicos de aprendizado} % Caption
    {quiza-2012-finite-element} % Citation

De uma maneira análoga, a \acrshort{ann} é composta por um conjunto de unidades simples densamente interconectadas e organizadas em camadas, que exercem o papel dos neurônios, conforme ilustra a \autoref{fig:rede-neural}.
Cada unidade recebe como entrada um conjunto de números reais -- geralmente produzidos por unidades da camada anterior -- e produz como saída um outro conjunto de números reais -- que poderão ser utilizados pelas unidades da camada seguinte.
Além disso, cada conexão entre essas unidades recebe um peso, que é um número real que representa a importância daquela conexão. Esses pesos são ajustados à medida em que a \acrshort{ann} adapta-se aos padrões existentes nos dados, ou seja, conforme ela aprende acerca do domínio do problema em questão.

\figura[p. 43]
    {fig:rede-neural} % Label
    {capitulos/fundamentacao/imagens/rede_neural_2} % Path
    {height=7cm} % Size
    {Exemplo de \acrfull{ann} com 4 camadas interconectadas: os dados \(\{X_1, X_2, \dots, X_k\}\) são recebidos pelas unidades da camada de entrada (ou \textit{input layer}), processados pelas camadas ocultas (ou \textit{hidden layers}) e pela camada de saída (ou \textit{output layer}) que, por sua vez, produz as saídas \(\{Y_1, Y_2, \dots, Y_k\}\)} % Caption
    {quiza-2012-finite-element} % Citation


\citeonline{lecun-2015-deep-learning,russell-2010-modern-approach} comentam que a forma mais utilizada de aprendizado pelas \acrshortpl{ann} é o aprendizado supervisionado, no qual a partir da observação de um conjunto de amostras de pares de entrada-saída, a rede aprende uma função que mapeia daquele tipo de entrada para aquela saída respectiva, ajustando seus pesos de acordo.

Por exemplo, imagine a construção de uma \acrshort{ann} para identificar em imagens a existência de casas, carros, pessoas ou animais de estimação. O primeiro passo consistiria em coletar um grande conjunto de imagens de casas, carros, pessoas e animais de estimação, cada uma identificada quanto à existência de um desses elementos -- formando assim os pares de entrada-saída mencionados acima que, nesse contexto, seriam pares de ``imagem-elemento''.
Esse conjunto de imagens (ou amostras) é dividido em dois subconjuntos: um de treinamento -- utilizado para que a \acrshort{ann} aprenda a identificar esses elementos --, e outro de testes -- utilizado para avaliar o sucesso da rede nesse processo de aprendizado.

O próximo passo consistiria em realizar o treinamento da \acrshort{ann}, para o qual será aplicada a técnica de aprendizado supervisionado e utilizado o subconjunto de imagens de treinamento estabelecido acima.
Nesse processo, a rede visitará cada uma dessas imagens e produzirá uma pontuação com a probabilidade de existência um dos elementos possíveis naquela imagem -- casa, carro, pessoa ou animal de estimação.
Objetiva-se que aquele elemento que está presente na imagem receba a maior pontuação e os demais elementos recebam pontuações menores, mas isso apenas ocorrerá à medida que os pesos da rede forem sendo ajustados para tal.
Esse processo de ajuste de pesos é denominado otimização da \acrshort{ann} e, para que ele ocorra, é necessário que seja introduzida uma função capaz de computar o erro ou a distância entre as pontuações informadas pela rede e aquelas que refletem o padrão correto desejado.
A essa função atribui-se o nome de função objetivo -- a qual também é conhecida como função de perda ou função de custo.


% Otimização
\citeonline{lecun-2015-deep-learning,goodfellow-2016-deep-learning} afirmam que um dos algoritmos de otimização mais utilizados é o \acrfull{sgd}.
De uma forma simplificada, ele consiste num processo de apresentar pequenos \textit{batches} (ou lotes) de amostras para a \acrshort{ann}, computar as respectivas pontuações e erros (pela função objetivo), computar os gradientes para cada um dos pesos da rede (os quais indicam o quanto o erro aumentaria ou diminuiria se os pesos fossem ajustados em uma pequena quantidade) e ajustar os pesos na direção oposta à dos gradientes.
Esse processo é repetido para vários \textit{batches} de amostras do subconjunto de treinamento até que o erro médio pare de diminuir.
Uma vez que o menor erro médio é encontrado, assume-se que o treinamento da \acrshort{ann} está finalizado.

Por fim, o desempenho da \acrshort{ann} será avaliado utilizando-se a mesma função objetivo para calcular o erro médio porém para um subconjunto diferente de amostras -- o subconjunto de testes, estabelecido acima.
Isso permitirá conhecer a capacidade de generalização da rede, ou seja, o quanto ela é bem-sucedida ao tentar produzir respostas sensatas para amostras nunca antes observadas.

Apesar disso, \citeonline{goodfellow-2016-deep-learning,bishop-2006-pattern-recognition} argumentam que essa divisão das amostras em apenas dois subconjuntos fixos, de treinamento e de testes, pode ser problemático principalmente se isso resultar em um subconjunto de testes pequeno.
Isso implicaria incerteza estatística em torno do erro médio de testes estimado, tornando difícil afirmar que um algoritmo funciona melhor que outro na tarefa em questão.
Para lidar com esse problema, é possível que seja aplicado um procedimento conhecido como validação cruzada, o qual permite com que todas as amostras sejam utilizadas nesse processo de testes ou estimativa de erro médio.

Os algoritmos de validação cruzada baseiam-se na ideia de repetir as etapas de treinamento e testes utilizando subconjuntos diferentes de amostras, escolhidos aleatoriamente a partir do conjunto original, e computando o erro a partir da média dos erros obtidos em cada repetição. 
O mais comum desses algoritmos é o \textit{\(k\)-fold}, que funciona dividindo o conjunto de dados original em \(k\) subconjuntos não sobrepostos e realizando \(k\) repetições de treinamento e testes. 
A cada repetição \(i\), o \(i\)-ésimo subconjunto é utilizado como subconjunto de testes e o restante dos dados é utilizado como o de treinamento, e assim por diante.
O erro médio é então estimado tomando-se a média dos erros obtidos nessas \(k\) repetições.


% Busca de parâmetros

Segundo \citeonline{goodfellow-2016-deep-learning}, a maioria das \acrshortpl{ann} também apresenta parâmetros que controlam diferentes aspectos do seu comportamento, os quais são denominados hiperparâmetros.
Exemplos deles incluem o número de camadas da rede, as dimensões dessas camadas, a taxa de aprendizagem e o tamanho dos \textit{batches} adotados no treinamento, entre outros que variam de acordo com o tipo de \acrshort{ann}.
Contudo, diferentemente do que ocorre para os pesos da rede, esses hiperparâmetros não são aprendidos automaticamente durante o processo de treinamento. 
Ao contrário, a escolha dos valores de hiperparâmetros que melhor otimizam a capacidade da rede é geralmente uma tarefa complexa porque demanda uma compreensão mais profunda acerca do papel que eles exercem sobre o desempenho da rede.


Por conta disso, é comum que sejam adotadas abordagens automáticas para essa finalidade, a exemplo do algoritmo \textit{grid search} (ou busca de grade) -- que será utilizado mais adiante nos experimentos deste trabalho.
O \textit{grid search} funciona com base num conjunto pequeno e finito de valores a serem explorados para cada um dos hiperparâmetros da rede, os quais são informados pelo usuário ao início da busca.
Com base nisso, o algoritmo gera o produto cartesiano de todas as combinações possíveis desses valores de hiperparâmetros e, em seguida, treina uma rede neural para cada uma dessas combinações.
Ao final desse processo, a rede neural que apresentar o menor erro médio é então considerada aquela que encontrou a melhor combinação de valores de hiperparâmetros.
Obviamente, um problema relevante desse algoritmo é o seu custo computacional, que cresce exponencialmente em função do número de hiperparâmetros e de valores a serem explorados.

Para essa seleção automática de hiperparâmetros é introduzido um novo subconjunto de amostras denominado subconjunto de validação.
Ele é importante para evitar que nesse processo sejam utilizadas as mesmas amostras para treinar e validar o desempenho das redes para cada combinação de hiperparâmetros.
Sendo assim, esse subconjunto é criado a partir de uma divisão do subconjunto de treinamento na qual, tipicamente, 20\% das amostras são direcionadas para validação de hiperparâmetros e 80\% permanecem sendo utilizadas para treinamento.
O subconjunto de testes, por sua vez, permanece inalterado e não é envolvido na seleção de hiperparâmetros.
