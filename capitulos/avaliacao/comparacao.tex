\section{Comparação dos resultados}
\label{sec:comparacao-resultados}

Para estabelecer um comparativo entre os resultados deste trabalho e outras pesquisas dentro da área de \acrfull{slr}, foram selecionados estudos que também utilizaram o \acrshort{asllvd} como referência em seus experimentos.
Esses estudos são enumerados a seguir:


\begin{itemize}
      \item \textbf{\citeonline{theodorakis-2014-dynamic-static}}: utiliza técnicas não-supervisionadas e também \acrfull{hmm} para gerar subunidades de movimento e pausa (chamadas 2-S-U) que são utilizadas para reconhecer os sinais.
            Para isso, os autores processam os \textit{frames} das amostras concentrando-se apenas nas mãos dos indivíduos e selecionam um subconjunto de 97 sinais do \acrshort{asllvd}.
 
      \item \textbf{\citeonline{lim-2016-bhof}}: introduz a técnica de \acrfull{bhof}, que gera histogramas do fluxo óptico das mãos dos indivíduos a partir dos \textit{frames} das amostras.
            Em seus experimentos, os autores selecionam um subconjunto de apenas 20 sinais do \acrshort{asllvd}.

            Além disso, eles também comparam os resultados do \acrshort{bhof} com aqueles obtidos pelas técnicas \acrfull{mei}, \acrfull{mhi}, \acrfull{pca} e \acrfull{hof} para o mesmo subconjunto de sinais.
 
      \item \textbf{\citeonline{metaxas-2018-linguistically}}: combina uma variedade de técnicas com o intuito de produzir diferentes \textit{features} referentes a configuração de mão inicial e final; número de mãos envolvidas; distância entre mãos; coordenadas 3D do corpo, face, mãos e braços; e contato das mãos com o corpo.
            Essas \textit{features} são utilizadas como entrada para um modelo baseado em \acrfull{hcorf} para reconhecer um subconjunto selecionado de 350 sinais do \acrshort{asllvd}.
 
      \item \textbf{\citeonline{lim-2019-isolated-slr-cnn-hei}}: introduz uma representação chamada \acrfull{hei} que também concentra-se nas mãos dos indivíduos e é utilizada como entrada para uma rede \acrfull{cnn}.
            Os autores adotam o mesmo subconjunto de 20 sinais utilizados por \citeonline{lim-2016-bhof} acima.
 
      \item \textbf{\citeonline{amorim-2019-stgcn-sl}}: utiliza grafos para modelar a dimensão espacial das coordenadas 2D do corpo dos indivíduos bem como a relação temporal dos seus movimentos, os quais são fornecidos como entrada para uma rede \acrfull{stgcn}.
            Os autores avaliam os resultados para o mesmo subconjunto de 20 sinais definidos por \citeonline{lim-2016-bhof}, mas também para o \acrshort{asllvd} inteiro.
\end{itemize}


Como pode-se perceber pela introdução acima, a maioria desses estudos aborda o \acrshort{slr} através do processamento de dados brutos -- como \textit{frames} RGB ou coordenadas 2D ou 3D --, conforme discutido ao longo da \autoref{sec:slr}.
Apesar de em alguns casos eles serem utilizados para gerar \textit{features} intermediárias -- como subunidades de movimento e pausa, imagens de fluxo óptico ou de energia de movimento, histogramas, grafos, entre outras -- estas, por sua vez, apresentam ainda um nível semântico muito menos informativo quanto à língua de sinais e à sua linguística do que aquelas que introduzimos neste trabalho.

Além disso, parte desses trabalhos concentra-se apenas nas mãos dos indivíduos e isso nos remete a um dos problemas discutidos na \autoref{sec:slr-desafios}, que se refere à abordagem inadequada no reconhecimento da língua de sinais. Como resultado, traços linguísticos importantes -- como expressões não-manuais, locação de mãos, movimentos do corpo e interações entre mãos e corpo -- acabam sendo desconsiderados.

Observa-se também que todos esses trabalhos modelam vocabulários que correspondem a subconjuntos muito pequenos do \acrshort{asllvd}, conforme discutido na \autoref{sec:slr-breve-panorama}.
Esses subconjuntos, por sua vez, representam menos de 13\% do vocabulário total de 2.745 sinais disponibilizado por esse \textit{dataset} e isso faz com que eles acabem não abrangendo uma amplitude significativa da língua de sinais.

Compreende-se que todos esses fatores têm por objetivo simplificar o tamanho e a complexidade do escopo abordado pelas pesquisas acima. No entanto, é inevitável ressaltar após a discussão realizada ao longo deste trabalho que recortes assim distanciam tais pesquisas do contexto real de uso da língua de sinais e, consequentemente, limitam o nível das contribuições que efetivamente agregam avanços à área de \acrshort{slr}.


\input{capitulos/avaliacao/tabelas/comparacao-resultados}


A \autoref{tab:comparacao-resultados} relaciona os resultados apresentados pelos estudos introduzidos acima e os obtidos pelos modelos utilizados nos experimentos deste trabalho.
De uma maneira geral, observa-se que os modelos \textit{Encoder-Decoders} utilizados aqui posicionaram-se com um desempenho superior com relação à maioria das pesquisas: sua acurácia de aproximadamente 88\% ultrapassou técnicas como \acrshort{bhof}, \acrshort{hof}, 2-S-U + \acrshort{hmm} e \acrshort{stgcn}; contudo, a técnica de \acrshort{hcorf} mostrou-se ainda superior alcançando 93,30\%.
Por sua vez, a acurácia de 100,00\% registrada pelo \textit{Transformer} posicionou-se consistentemente superior aos demais resultados da tabela.

Quando considerados apenas os estudos que modelaram \textit{features} referentes ao corpo inteiro do indivíduo (mesmo que indiretamente através de dados brutos como coordenadas) em vez de apenas suas mãos, tem-se uma perspectiva diferente. \citeonline{metaxas-2018-linguistically} e \citeonline{amorim-2019-stgcn-sl} se enquadram nesses critérios e, pela tabela, observa-se que enquanto a técnica de \acrshort{hcorf} superou os resultados das implementações de \textit{Encoder-Decoders} utilizadas em nossos experimentos, o \acrshort{stgcn} registrou uma acurácia inferior de 61,04\%.

É importante salientar que a maioria dos estudos na tabela modelam vocabulários muito pequenos do \acrshort{asllvd}, o que difere-se do que foi realizado neste trabalho. Conforme discutido acima, esse tipo de abordagem fornece um recorte simplificado do problema e favorece para que tais estudos alcancem acurácias mais elevadas.
Os números apresentados por \citeonline{amorim-2019-stgcn-sl} ajudam a ilustrar a diferença decorrente disso: ao modelar os 20 sinais utilizados pela maioria dos estudos na tabela, o \acrshort{stgcn} obteve uma acurácia de 61,04\%; no entanto, quando utilizados os 2.745 sinais, esse número caiu para 16,48\%.
Dessa forma, entende-se que mesmo as acurácias de 87,21\% e 88,00\% obtidas pelos \textit{Encoder-Decoders} nos experimentos deste trabalho representam resultados bastante significativos em comparação com os demais estudos na tabela, uma vez que aqui abordou-se um vocabulário complexo de 2.650 sinais e os demais consideraram apenas recortes de 20, 97 ou 350 sinais.
